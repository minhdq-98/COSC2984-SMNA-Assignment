{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593f174c-f5ba-4fc0-904b-357c3c4aaa79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:38:38.580998Z",
     "iopub.status.busy": "2025-05-22T09:38:38.580883Z",
     "iopub.status.idle": "2025-05-22T09:38:39.826594Z",
     "shell.execute_reply": "2025-05-22T09:38:39.826081Z",
     "shell.execute_reply.started": "2025-05-22T09:38:38.580987Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f981cf30-67ef-41a3-bf4f-32128c39f8a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:38:47.739655Z",
     "iopub.status.busy": "2025-05-22T09:38:47.739396Z",
     "iopub.status.idle": "2025-05-22T09:38:49.175542Z",
     "shell.execute_reply": "2025-05-22T09:38:49.175070Z",
     "shell.execute_reply.started": "2025-05-22T09:38:47.739643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as quangbhdang\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as quangbhdang\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"quangbhdang/COSC2984-SMNA-Assignment\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"quangbhdang/COSC2984-SMNA-Assignment\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository quangbhdang/COSC2984-SMNA-Assignment initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository quangbhdang/COSC2984-SMNA-Assignment initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='quangbhdang', repo_name='COSC2984-SMNA-Assignment', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877500ca-e7a2-40b5-9957-f581edf00e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T08:52:56.181799Z",
     "iopub.status.busy": "2025-05-22T08:52:56.181547Z",
     "iopub.status.idle": "2025-05-22T08:52:56.184755Z",
     "shell.execute_reply": "2025-05-22T08:52:56.184154Z",
     "shell.execute_reply.started": "2025-05-22T08:52:56.181787Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Upload using the DagsHub client, to a DVC tracked folder also called \"data\".\n",
    "# # Follow the instructions that appear to authorize the request.\n",
    "# from dagshub import upload_files\n",
    "\n",
    "# dagshub.upload_files('quangbhdang/COSC2984-SMNA-Assignment', 'Dataset/So-Spam/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f33b424-2768-4597-9fbb-7b5ae38f42f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:38:44.249844Z",
     "iopub.status.busy": "2025-05-22T09:38:44.249536Z",
     "iopub.status.idle": "2025-05-22T09:38:44.254561Z",
     "shell.execute_reply": "2025-05-22T09:38:44.254092Z",
     "shell.execute_reply.started": "2025-05-22T09:38:44.249832Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch, model):\n",
    "    model.train()\n",
    "    output = model(des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type)\n",
    "    loss_train = loss(output[train_idx], labels[train_idx])\n",
    "    acc_train = accuracy(output[train_idx], labels[train_idx])\n",
    "    acc_val = accuracy(output[val_idx], labels[val_idx])\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "        'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "        'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "        'acc_val: {:.4f}'.format(acc_val.item()),)\n",
    "    return acc_train,loss_train\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    output = model(des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type)\n",
    "    loss_test = loss(output[test_idx], labels[test_idx])\n",
    "    acc_test = accuracy(output[test_idx], labels[test_idx])\n",
    "    output=output.max(1)[1].to('cpu').detach().numpy()\n",
    "    label=labels.to('cpu').detach().numpy()\n",
    "    f1=f1_score(label[test_idx],output[test_idx])\n",
    "    mcc=matthews_corrcoef(label[test_idx], output[test_idx])\n",
    "    print(\"Test set results:\",\n",
    "            \"test_loss= {:.4f}\".format(loss_test.item()),\n",
    "            \"test_accuracy= {:.4f}\".format(acc_test.item()),\n",
    "            \"f1_score= {:.4f}\".format(f1),\n",
    "            \"mcc= {:.4f}\".format(mcc),\n",
    "            )\n",
    "    return acc_test,loss_test,f1, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb27d90-aec3-46ab-92f2-8d3f63061085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:38:50.720421Z",
     "iopub.status.busy": "2025-05-22T09:38:50.719935Z",
     "iopub.status.idle": "2025-05-22T09:39:43.821404Z",
     "shell.execute_reply": "2025-05-22T09:39:43.820869Z",
     "shell.execute_reply.started": "2025-05-22T09:38:50.720408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels...   Finished\n",
      "Running feature1 embedding\n",
      "Finished\n",
      "Running feature2 embedding\n",
      "Finished\n",
      "Processing feature3...   Finished\n",
      "Processing feature4...   Finished\n",
      "Building feature-based graph from all features (chunked)...   Finished\n",
      "Epoch: 0001 loss_train: 0.9123 acc_train: 0.5145 acc_val: 0.5209\n",
      "Epoch: 0002 loss_train: 1.1311 acc_train: 0.5935 acc_val: 0.5835\n",
      "Epoch: 0003 loss_train: 0.7247 acc_train: 0.6707 acc_val: 0.6567\n",
      "Epoch: 0004 loss_train: 0.6245 acc_train: 0.6753 acc_val: 0.6490\n",
      "Epoch: 0005 loss_train: 0.7013 acc_train: 0.6069 acc_val: 0.5865\n",
      "Epoch: 0006 loss_train: 0.6792 acc_train: 0.6149 acc_val: 0.5932\n",
      "Epoch: 0007 loss_train: 0.5917 acc_train: 0.6851 acc_val: 0.6727\n",
      "Epoch: 0008 loss_train: 0.5267 acc_train: 0.7603 acc_val: 0.7400\n",
      "Epoch: 0009 loss_train: 0.5187 acc_train: 0.7870 acc_val: 0.7649\n",
      "Epoch: 0010 loss_train: 0.5307 acc_train: 0.7867 acc_val: 0.7700\n",
      "Epoch: 0011 loss_train: 0.5431 acc_train: 0.7844 acc_val: 0.7755\n",
      "Epoch: 0012 loss_train: 0.5164 acc_train: 0.7890 acc_val: 0.7789\n",
      "Epoch: 0013 loss_train: 0.4773 acc_train: 0.7961 acc_val: 0.7797\n",
      "Epoch: 0014 loss_train: 0.4599 acc_train: 0.7922 acc_val: 0.7738\n",
      "Epoch: 0015 loss_train: 0.4679 acc_train: 0.7832 acc_val: 0.7683\n",
      "Epoch: 0016 loss_train: 0.4659 acc_train: 0.7758 acc_val: 0.7662\n",
      "Epoch: 0017 loss_train: 0.4644 acc_train: 0.7869 acc_val: 0.7767\n",
      "Epoch: 0018 loss_train: 0.4386 acc_train: 0.8053 acc_val: 0.7882\n",
      "Epoch: 0019 loss_train: 0.4338 acc_train: 0.8071 acc_val: 0.7911\n",
      "Epoch: 0020 loss_train: 0.4251 acc_train: 0.8090 acc_val: 0.7996\n",
      "Epoch: 0021 loss_train: 0.4291 acc_train: 0.8108 acc_val: 0.7928\n",
      "Epoch: 0022 loss_train: 0.4270 acc_train: 0.8148 acc_val: 0.7928\n",
      "Epoch: 0023 loss_train: 0.4270 acc_train: 0.8154 acc_val: 0.8021\n",
      "Epoch: 0024 loss_train: 0.4119 acc_train: 0.8204 acc_val: 0.8051\n",
      "Epoch: 0025 loss_train: 0.4037 acc_train: 0.8298 acc_val: 0.8148\n",
      "Epoch: 0026 loss_train: 0.4000 acc_train: 0.8268 acc_val: 0.8178\n",
      "Epoch: 0027 loss_train: 0.3984 acc_train: 0.8335 acc_val: 0.8288\n",
      "Epoch: 0028 loss_train: 0.3938 acc_train: 0.8340 acc_val: 0.8182\n",
      "Epoch: 0029 loss_train: 0.3911 acc_train: 0.8363 acc_val: 0.8279\n",
      "Epoch: 0030 loss_train: 0.3849 acc_train: 0.8407 acc_val: 0.8283\n",
      "Epoch: 0031 loss_train: 0.3824 acc_train: 0.8407 acc_val: 0.8317\n",
      "Epoch: 0032 loss_train: 0.3832 acc_train: 0.8426 acc_val: 0.8334\n",
      "Epoch: 0033 loss_train: 0.3843 acc_train: 0.8403 acc_val: 0.8288\n",
      "Epoch: 0034 loss_train: 0.3740 acc_train: 0.8440 acc_val: 0.8364\n",
      "Epoch: 0035 loss_train: 0.3722 acc_train: 0.8444 acc_val: 0.8355\n",
      "Epoch: 0036 loss_train: 0.3672 acc_train: 0.8461 acc_val: 0.8330\n",
      "Epoch: 0037 loss_train: 0.3676 acc_train: 0.8479 acc_val: 0.8326\n",
      "Epoch: 0038 loss_train: 0.3674 acc_train: 0.8430 acc_val: 0.8288\n",
      "Epoch: 0039 loss_train: 0.3614 acc_train: 0.8475 acc_val: 0.8347\n",
      "Epoch: 0040 loss_train: 0.3612 acc_train: 0.8480 acc_val: 0.8355\n",
      "Epoch: 0041 loss_train: 0.3581 acc_train: 0.8480 acc_val: 0.8389\n",
      "Epoch: 0042 loss_train: 0.3555 acc_train: 0.8501 acc_val: 0.8431\n",
      "Epoch: 0043 loss_train: 0.3566 acc_train: 0.8500 acc_val: 0.8355\n",
      "Epoch: 0044 loss_train: 0.3523 acc_train: 0.8483 acc_val: 0.8406\n",
      "Epoch: 0045 loss_train: 0.3498 acc_train: 0.8489 acc_val: 0.8427\n",
      "Epoch: 0046 loss_train: 0.3490 acc_train: 0.8525 acc_val: 0.8376\n",
      "Epoch: 0047 loss_train: 0.3462 acc_train: 0.8504 acc_val: 0.8431\n",
      "Epoch: 0048 loss_train: 0.3403 acc_train: 0.8564 acc_val: 0.8406\n",
      "Epoch: 0049 loss_train: 0.3395 acc_train: 0.8535 acc_val: 0.8440\n",
      "Epoch: 0050 loss_train: 0.3409 acc_train: 0.8535 acc_val: 0.8444\n",
      "Epoch: 0051 loss_train: 0.3376 acc_train: 0.8566 acc_val: 0.8436\n",
      "Epoch: 0052 loss_train: 0.3345 acc_train: 0.8547 acc_val: 0.8414\n",
      "Epoch: 0053 loss_train: 0.3353 acc_train: 0.8538 acc_val: 0.8495\n",
      "Epoch: 0054 loss_train: 0.3300 acc_train: 0.8597 acc_val: 0.8448\n",
      "Epoch: 0055 loss_train: 0.3302 acc_train: 0.8566 acc_val: 0.8427\n",
      "Epoch: 0056 loss_train: 0.3301 acc_train: 0.8583 acc_val: 0.8457\n",
      "Epoch: 0057 loss_train: 0.3274 acc_train: 0.8597 acc_val: 0.8440\n",
      "Epoch: 0058 loss_train: 0.3260 acc_train: 0.8568 acc_val: 0.8516\n",
      "Epoch: 0059 loss_train: 0.3254 acc_train: 0.8582 acc_val: 0.8478\n",
      "Epoch: 0060 loss_train: 0.3193 acc_train: 0.8648 acc_val: 0.8507\n",
      "Epoch: 0061 loss_train: 0.3204 acc_train: 0.8620 acc_val: 0.8465\n",
      "Epoch: 0062 loss_train: 0.3184 acc_train: 0.8602 acc_val: 0.8486\n",
      "Epoch: 0063 loss_train: 0.3136 acc_train: 0.8630 acc_val: 0.8533\n",
      "Epoch: 0064 loss_train: 0.3152 acc_train: 0.8617 acc_val: 0.8469\n",
      "Epoch: 0065 loss_train: 0.3130 acc_train: 0.8648 acc_val: 0.8520\n",
      "Epoch: 0066 loss_train: 0.3107 acc_train: 0.8695 acc_val: 0.8516\n",
      "Epoch: 0067 loss_train: 0.3115 acc_train: 0.8641 acc_val: 0.8545\n",
      "Epoch: 0068 loss_train: 0.3086 acc_train: 0.8664 acc_val: 0.8512\n",
      "Epoch: 0069 loss_train: 0.3057 acc_train: 0.8674 acc_val: 0.8495\n",
      "Epoch: 0070 loss_train: 0.3060 acc_train: 0.8682 acc_val: 0.8516\n",
      "Epoch: 0071 loss_train: 0.3016 acc_train: 0.8718 acc_val: 0.8541\n",
      "Epoch: 0072 loss_train: 0.3024 acc_train: 0.8687 acc_val: 0.8596\n",
      "Epoch: 0073 loss_train: 0.3025 acc_train: 0.8691 acc_val: 0.8490\n",
      "Epoch: 0074 loss_train: 0.3024 acc_train: 0.8697 acc_val: 0.8579\n",
      "Epoch: 0075 loss_train: 0.2966 acc_train: 0.8715 acc_val: 0.8537\n",
      "Epoch: 0076 loss_train: 0.2973 acc_train: 0.8707 acc_val: 0.8537\n",
      "Epoch: 0077 loss_train: 0.2945 acc_train: 0.8739 acc_val: 0.8575\n",
      "Epoch: 0078 loss_train: 0.2946 acc_train: 0.8717 acc_val: 0.8507\n",
      "Epoch: 0079 loss_train: 0.2930 acc_train: 0.8751 acc_val: 0.8660\n",
      "Epoch: 0080 loss_train: 0.2882 acc_train: 0.8733 acc_val: 0.8626\n",
      "Epoch: 0081 loss_train: 0.2912 acc_train: 0.8718 acc_val: 0.8596\n",
      "Epoch: 0082 loss_train: 0.2885 acc_train: 0.8765 acc_val: 0.8575\n",
      "Epoch: 0083 loss_train: 0.2918 acc_train: 0.8729 acc_val: 0.8596\n",
      "Epoch: 0084 loss_train: 0.2873 acc_train: 0.8767 acc_val: 0.8550\n",
      "Epoch: 0085 loss_train: 0.2867 acc_train: 0.8746 acc_val: 0.8613\n",
      "Epoch: 0086 loss_train: 0.2854 acc_train: 0.8769 acc_val: 0.8643\n",
      "Epoch: 0087 loss_train: 0.2815 acc_train: 0.8761 acc_val: 0.8596\n",
      "Epoch: 0088 loss_train: 0.2817 acc_train: 0.8798 acc_val: 0.8605\n",
      "Epoch: 0089 loss_train: 0.2839 acc_train: 0.8794 acc_val: 0.8605\n",
      "Epoch: 0090 loss_train: 0.2772 acc_train: 0.8809 acc_val: 0.8634\n",
      "Epoch: 0091 loss_train: 0.2776 acc_train: 0.8781 acc_val: 0.8579\n",
      "Epoch: 0092 loss_train: 0.2763 acc_train: 0.8822 acc_val: 0.8558\n",
      "Epoch: 0093 loss_train: 0.2739 acc_train: 0.8797 acc_val: 0.8584\n",
      "Epoch: 0094 loss_train: 0.2773 acc_train: 0.8815 acc_val: 0.8558\n",
      "Epoch: 0095 loss_train: 0.2728 acc_train: 0.8827 acc_val: 0.8677\n",
      "Epoch: 0096 loss_train: 0.2707 acc_train: 0.8813 acc_val: 0.8579\n",
      "Epoch: 0097 loss_train: 0.2691 acc_train: 0.8813 acc_val: 0.8609\n",
      "Epoch: 0098 loss_train: 0.2693 acc_train: 0.8860 acc_val: 0.8600\n",
      "Epoch: 0099 loss_train: 0.2677 acc_train: 0.8827 acc_val: 0.8600\n",
      "Epoch: 0100 loss_train: 0.2629 acc_train: 0.8857 acc_val: 0.8655\n",
      "Test set results: test_loss= 0.3206 test_accuracy= 0.8580 f1_score= 0.8731 mcc= 0.7143\n"
     ]
    }
   ],
   "source": [
    "from Src.Dataset import Twibot20\n",
    "from Src.model import BotRGCN\n",
    "import torch\n",
    "from torch import nn\n",
    "from Src.utils import accuracy, init_weights\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "embedding_size,dropout,lr,weight_decay=128,0.3,1e-3,5e-3\n",
    "\n",
    "dataset= Twibot20(device=device ,process=False)\n",
    "des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type,labels,train_idx,val_idx,test_idx=dataset.dataloader(build_feature_graph=True)\n",
    "\n",
    "botRGCN=BotRGCN(num_prop_size=5,cat_prop_size=3,embedding_dimension=embedding_size).to(device)\n",
    "\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(botRGCN.parameters(),\n",
    "                    lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "botRGCN.apply(init_weights)\n",
    "\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    acc_train, loss_train = train(epoch,botRGCN)\n",
    "    \n",
    "acc_test, loss_test, f1, mcc = test(botRGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7161437-8f38-4c8a-a153-b806b77662d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:41:01.639394Z",
     "iopub.status.busy": "2025-05-22T09:41:01.638917Z",
     "iopub.status.idle": "2025-05-22T09:41:03.621962Z",
     "shell.execute_reply": "2025-05-22T09:41:03.621389Z",
     "shell.execute_reply.started": "2025-05-22T09:41:01.639377Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 16:41:03 INFO mlflow.tracking.fluent: Experiment with name 'Dang_TwiBot20_624157' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/767f283567aa4f70b42d159094f7c847', creation_time=1747906863301, experiment_id='7', last_update_time=1747906863301, lifecycle_stage='active', name='Dang_TwiBot20_624157', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import uuid\n",
    "\n",
    "# Optional: set a custom or unique experiment name\n",
    "experiment_name = f\"Dang_TwiBot20_{uuid.uuid4().hex[:6]}\"\n",
    "mlflow.set_experiment(experiment_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9198336b-fb0d-484f-9d9e-e089fe99e829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:42:04.349658Z",
     "iopub.status.busy": "2025-05-22T09:42:04.349327Z",
     "iopub.status.idle": "2025-05-22T09:42:15.695481Z",
     "shell.execute_reply": "2025-05-22T09:42:15.694977Z",
     "shell.execute_reply.started": "2025-05-22T09:42:04.349638Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 16:42:07 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/22 16:42:11 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/05/22 16:42:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run youthful-shrimp-498 at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/7/runs/4b6c298b01d14c3ea3ff0096580e0ddf\n",
      "🧪 View experiment at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/7\n"
     ]
    }
   ],
   "source": [
    "# Logging experiment results\n",
    "\n",
    "run_description = \"Bot RGCN with custom feature based graph encoding instead of relationship\"\n",
    "\n",
    "with mlflow.start_run(description=run_description):\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"embedding_size\": embedding_size,\n",
    "        \"dropout\": dropout,\n",
    "        \"learning_rate\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"epochs\": epochs\n",
    "    })\n",
    "\n",
    "    # Log final test metrics (replace with your actual variable values)\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\":acc_train.item() if isinstance(acc_train, torch.Tensor) else acc_train,\n",
    "        \"train_loss\": loss_train.item() if isinstance(acc_train, torch.Tensor) else loss_train,\n",
    "        \"test_accuracy\": acc_test.item() if isinstance(acc_test, torch.Tensor) else acc_test,\n",
    "        \"test_loss\": loss_test.item() if isinstance(loss_test, torch.Tensor) else loss_test,\n",
    "        \"f1_score\": f1,\n",
    "        \"matthew_coeff\": mcc\n",
    "        \n",
    "    })\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(botRGCN)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    # Optionally log model\n",
    "    mlflow.pytorch.log_model(botRGCN, \"BotRGCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb3ee693-01ea-4399-b07b-a026f97f8a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:42:23.103401Z",
     "iopub.status.busy": "2025-05-22T09:42:23.102919Z",
     "iopub.status.idle": "2025-05-22T09:42:28.162842Z",
     "shell.execute_reply": "2025-05-22T09:42:28.162351Z",
     "shell.execute_reply.started": "2025-05-22T09:42:23.103386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.6836 acc_train: 0.5754 acc_val: 0.5700\n",
      "Epoch: 0002 loss_train: 0.6685 acc_train: 0.5935 acc_val: 0.5839\n",
      "Epoch: 0003 loss_train: 0.6557 acc_train: 0.6046 acc_val: 0.5979\n",
      "Epoch: 0004 loss_train: 0.6422 acc_train: 0.6148 acc_val: 0.6089\n",
      "Epoch: 0005 loss_train: 0.6269 acc_train: 0.6540 acc_val: 0.6461\n",
      "Epoch: 0006 loss_train: 0.6086 acc_train: 0.7315 acc_val: 0.7235\n",
      "Epoch: 0007 loss_train: 0.5908 acc_train: 0.7675 acc_val: 0.7480\n",
      "Epoch: 0008 loss_train: 0.5710 acc_train: 0.7747 acc_val: 0.7543\n",
      "Epoch: 0009 loss_train: 0.5506 acc_train: 0.7803 acc_val: 0.7658\n",
      "Epoch: 0010 loss_train: 0.5310 acc_train: 0.7879 acc_val: 0.7712\n",
      "Epoch: 0011 loss_train: 0.5096 acc_train: 0.7906 acc_val: 0.7780\n",
      "Epoch: 0012 loss_train: 0.4855 acc_train: 0.8031 acc_val: 0.7831\n",
      "Epoch: 0013 loss_train: 0.4615 acc_train: 0.8108 acc_val: 0.7928\n",
      "Epoch: 0014 loss_train: 0.4400 acc_train: 0.8210 acc_val: 0.8123\n",
      "Epoch: 0015 loss_train: 0.4235 acc_train: 0.8321 acc_val: 0.8275\n",
      "Epoch: 0016 loss_train: 0.4194 acc_train: 0.8288 acc_val: 0.8262\n",
      "Epoch: 0017 loss_train: 0.4579 acc_train: 0.8316 acc_val: 0.8262\n",
      "Epoch: 0018 loss_train: 0.4253 acc_train: 0.8218 acc_val: 0.8195\n",
      "Epoch: 0019 loss_train: 0.4288 acc_train: 0.8169 acc_val: 0.8211\n",
      "Epoch: 0020 loss_train: 0.4131 acc_train: 0.8395 acc_val: 0.8296\n",
      "Epoch: 0021 loss_train: 0.4207 acc_train: 0.8368 acc_val: 0.8326\n",
      "Epoch: 0022 loss_train: 0.3991 acc_train: 0.8382 acc_val: 0.8359\n",
      "Epoch: 0023 loss_train: 0.4078 acc_train: 0.8286 acc_val: 0.8292\n",
      "Epoch: 0024 loss_train: 0.3981 acc_train: 0.8338 acc_val: 0.8275\n",
      "Epoch: 0025 loss_train: 0.3926 acc_train: 0.8378 acc_val: 0.8288\n",
      "Epoch: 0026 loss_train: 0.3992 acc_train: 0.8334 acc_val: 0.8283\n",
      "Epoch: 0027 loss_train: 0.3926 acc_train: 0.8357 acc_val: 0.8283\n",
      "Epoch: 0028 loss_train: 0.3882 acc_train: 0.8360 acc_val: 0.8258\n",
      "Epoch: 0029 loss_train: 0.3948 acc_train: 0.8337 acc_val: 0.8271\n",
      "Epoch: 0030 loss_train: 0.3884 acc_train: 0.8349 acc_val: 0.8313\n",
      "Epoch: 0031 loss_train: 0.3841 acc_train: 0.8378 acc_val: 0.8317\n",
      "Epoch: 0032 loss_train: 0.3872 acc_train: 0.8396 acc_val: 0.8271\n",
      "Epoch: 0033 loss_train: 0.3845 acc_train: 0.8391 acc_val: 0.8334\n",
      "Epoch: 0034 loss_train: 0.3797 acc_train: 0.8426 acc_val: 0.8338\n",
      "Epoch: 0035 loss_train: 0.3808 acc_train: 0.8417 acc_val: 0.8317\n",
      "Epoch: 0036 loss_train: 0.3782 acc_train: 0.8395 acc_val: 0.8321\n",
      "Epoch: 0037 loss_train: 0.3762 acc_train: 0.8449 acc_val: 0.8334\n",
      "Epoch: 0038 loss_train: 0.3764 acc_train: 0.8431 acc_val: 0.8330\n",
      "Epoch: 0039 loss_train: 0.3749 acc_train: 0.8443 acc_val: 0.8347\n",
      "Epoch: 0040 loss_train: 0.3715 acc_train: 0.8442 acc_val: 0.8334\n",
      "Epoch: 0041 loss_train: 0.3733 acc_train: 0.8427 acc_val: 0.8334\n",
      "Epoch: 0042 loss_train: 0.3702 acc_train: 0.8438 acc_val: 0.8364\n",
      "Epoch: 0043 loss_train: 0.3682 acc_train: 0.8433 acc_val: 0.8364\n",
      "Epoch: 0044 loss_train: 0.3682 acc_train: 0.8456 acc_val: 0.8326\n",
      "Epoch: 0045 loss_train: 0.3669 acc_train: 0.8439 acc_val: 0.8376\n",
      "Epoch: 0046 loss_train: 0.3658 acc_train: 0.8424 acc_val: 0.8338\n",
      "Epoch: 0047 loss_train: 0.3641 acc_train: 0.8446 acc_val: 0.8347\n",
      "Epoch: 0048 loss_train: 0.3636 acc_train: 0.8462 acc_val: 0.8334\n",
      "Epoch: 0049 loss_train: 0.3630 acc_train: 0.8455 acc_val: 0.8359\n",
      "Epoch: 0050 loss_train: 0.3612 acc_train: 0.8466 acc_val: 0.8326\n",
      "Epoch: 0051 loss_train: 0.3612 acc_train: 0.8459 acc_val: 0.8368\n",
      "Epoch: 0052 loss_train: 0.3601 acc_train: 0.8448 acc_val: 0.8364\n",
      "Epoch: 0053 loss_train: 0.3600 acc_train: 0.8482 acc_val: 0.8334\n",
      "Epoch: 0054 loss_train: 0.3563 acc_train: 0.8480 acc_val: 0.8364\n",
      "Epoch: 0055 loss_train: 0.3565 acc_train: 0.8484 acc_val: 0.8359\n",
      "Epoch: 0056 loss_train: 0.3564 acc_train: 0.8463 acc_val: 0.8389\n",
      "Epoch: 0057 loss_train: 0.3552 acc_train: 0.8484 acc_val: 0.8385\n",
      "Epoch: 0058 loss_train: 0.3533 acc_train: 0.8502 acc_val: 0.8376\n",
      "Epoch: 0059 loss_train: 0.3541 acc_train: 0.8475 acc_val: 0.8359\n",
      "Epoch: 0060 loss_train: 0.3519 acc_train: 0.8486 acc_val: 0.8402\n",
      "Epoch: 0061 loss_train: 0.3509 acc_train: 0.8490 acc_val: 0.8364\n",
      "Epoch: 0062 loss_train: 0.3502 acc_train: 0.8490 acc_val: 0.8389\n",
      "Epoch: 0063 loss_train: 0.3472 acc_train: 0.8498 acc_val: 0.8347\n",
      "Epoch: 0064 loss_train: 0.3472 acc_train: 0.8517 acc_val: 0.8364\n",
      "Epoch: 0065 loss_train: 0.3475 acc_train: 0.8506 acc_val: 0.8385\n",
      "Epoch: 0066 loss_train: 0.3447 acc_train: 0.8515 acc_val: 0.8402\n",
      "Epoch: 0067 loss_train: 0.3458 acc_train: 0.8511 acc_val: 0.8368\n",
      "Epoch: 0068 loss_train: 0.3448 acc_train: 0.8543 acc_val: 0.8406\n",
      "Epoch: 0069 loss_train: 0.3424 acc_train: 0.8515 acc_val: 0.8393\n",
      "Epoch: 0070 loss_train: 0.3413 acc_train: 0.8531 acc_val: 0.8393\n",
      "Epoch: 0071 loss_train: 0.3408 acc_train: 0.8535 acc_val: 0.8376\n",
      "Epoch: 0072 loss_train: 0.3388 acc_train: 0.8536 acc_val: 0.8372\n",
      "Epoch: 0073 loss_train: 0.3388 acc_train: 0.8549 acc_val: 0.8368\n",
      "Epoch: 0074 loss_train: 0.3380 acc_train: 0.8537 acc_val: 0.8385\n",
      "Epoch: 0075 loss_train: 0.3366 acc_train: 0.8531 acc_val: 0.8376\n",
      "Epoch: 0076 loss_train: 0.3366 acc_train: 0.8543 acc_val: 0.8334\n",
      "Epoch: 0077 loss_train: 0.3341 acc_train: 0.8558 acc_val: 0.8372\n",
      "Epoch: 0078 loss_train: 0.3343 acc_train: 0.8548 acc_val: 0.8402\n",
      "Epoch: 0079 loss_train: 0.3322 acc_train: 0.8560 acc_val: 0.8393\n",
      "Epoch: 0080 loss_train: 0.3307 acc_train: 0.8560 acc_val: 0.8414\n",
      "Epoch: 0081 loss_train: 0.3296 acc_train: 0.8584 acc_val: 0.8342\n",
      "Epoch: 0082 loss_train: 0.3284 acc_train: 0.8566 acc_val: 0.8393\n",
      "Epoch: 0083 loss_train: 0.3267 acc_train: 0.8585 acc_val: 0.8393\n",
      "Epoch: 0084 loss_train: 0.3255 acc_train: 0.8568 acc_val: 0.8376\n",
      "Epoch: 0085 loss_train: 0.3234 acc_train: 0.8575 acc_val: 0.8393\n",
      "Epoch: 0086 loss_train: 0.3250 acc_train: 0.8582 acc_val: 0.8372\n",
      "Epoch: 0087 loss_train: 0.3240 acc_train: 0.8591 acc_val: 0.8376\n",
      "Epoch: 0088 loss_train: 0.3251 acc_train: 0.8572 acc_val: 0.8313\n",
      "Epoch: 0089 loss_train: 0.3261 acc_train: 0.8568 acc_val: 0.8359\n",
      "Epoch: 0090 loss_train: 0.3197 acc_train: 0.8583 acc_val: 0.8359\n",
      "Epoch: 0091 loss_train: 0.3179 acc_train: 0.8610 acc_val: 0.8381\n",
      "Epoch: 0092 loss_train: 0.3203 acc_train: 0.8597 acc_val: 0.8402\n",
      "Epoch: 0093 loss_train: 0.3166 acc_train: 0.8619 acc_val: 0.8334\n",
      "Epoch: 0094 loss_train: 0.3131 acc_train: 0.8622 acc_val: 0.8351\n",
      "Epoch: 0095 loss_train: 0.3138 acc_train: 0.8629 acc_val: 0.8359\n",
      "Epoch: 0096 loss_train: 0.3124 acc_train: 0.8626 acc_val: 0.8368\n",
      "Epoch: 0097 loss_train: 0.3086 acc_train: 0.8651 acc_val: 0.8355\n",
      "Epoch: 0098 loss_train: 0.3081 acc_train: 0.8642 acc_val: 0.8313\n",
      "Epoch: 0099 loss_train: 0.3082 acc_train: 0.8634 acc_val: 0.8351\n",
      "Epoch: 0100 loss_train: 0.3085 acc_train: 0.8648 acc_val: 0.8381\n",
      "Test set results: test_loss= 0.3734 test_accuracy= 0.8360 f1_score= 0.8548 mcc= 0.6703\n"
     ]
    }
   ],
   "source": [
    "from Src.model import BotGCN\n",
    "\n",
    "embedding_size,dropout,lr,weight_decay=128,0.3,1e-3,5e-3\n",
    "\n",
    "botGCN=BotGCN(num_prop_size=5,cat_prop_size=3,embedding_dimension=embedding_size).to(device)\n",
    "\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(botGCN.parameters(),\n",
    "                    lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "botRGCN.apply(init_weights)\n",
    "\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    acc_train, loss_train = train(epoch,botGCN)\n",
    "    \n",
    "acc_test, loss_test, f1, mcc = test(botGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b12be0-ae4b-4211-b618-8b8772ea59e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:43:09.666255Z",
     "iopub.status.busy": "2025-05-22T09:43:09.665957Z",
     "iopub.status.idle": "2025-05-22T09:43:20.257613Z",
     "shell.execute_reply": "2025-05-22T09:43:20.257064Z",
     "shell.execute_reply.started": "2025-05-22T09:43:09.666242Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 16:43:11 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/22 16:43:15 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/05/22 16:43:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run sincere-ray-269 at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/7/runs/2d3287e0e90748149a4cd63b7419b2bf\n",
      "🧪 View experiment at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/7\n"
     ]
    }
   ],
   "source": [
    "# Logging experiment results\n",
    "run_description = \"BotGCN with custom feature graph build instead of traditional graph\"\n",
    "with mlflow.start_run(description=run_description):\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"embedding_size\": embedding_size,\n",
    "        \"dropout\": dropout,\n",
    "        \"learning_rate\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"epochs\": epochs,\n",
    "        \"optimiser\": \"AdamW\"\n",
    "    })\n",
    "\n",
    "    # Log final test metrics (replace with your actual variable values)\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\":acc_train.item() if isinstance(acc_train, torch.Tensor) else acc_train,\n",
    "        \"train_loss\": loss_train.item() if isinstance(acc_train, torch.Tensor) else loss_train,\n",
    "        \"test_accuracy\": acc_test.item() if isinstance(acc_test, torch.Tensor) else acc_test,\n",
    "        \"test_loss\": loss_test.item() if isinstance(loss_test, torch.Tensor) else loss_test,\n",
    "        \"f1_score\": f1,\n",
    "        \"matthew_coeff\": mcc\n",
    "        \n",
    "    })\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(botGCN)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    # Optionally log model\n",
    "    mlflow.pytorch.log_model(botGCN, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e385260-f873-4a80-8af1-b62e21a70893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:44:02.088491Z",
     "iopub.status.busy": "2025-05-22T09:44:02.088166Z",
     "iopub.status.idle": "2025-05-22T09:44:09.098278Z",
     "shell.execute_reply": "2025-05-22T09:44:09.097750Z",
     "shell.execute_reply.started": "2025-05-22T09:44:02.088478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 1.0021 acc_train: 0.4391 acc_val: 0.4537\n",
      "Epoch: 0002 loss_train: 0.7826 acc_train: 0.5860 acc_val: 0.5890\n",
      "Epoch: 0003 loss_train: 0.7350 acc_train: 0.6103 acc_val: 0.6034\n",
      "Epoch: 0004 loss_train: 0.6059 acc_train: 0.7166 acc_val: 0.7171\n",
      "Epoch: 0005 loss_train: 0.5489 acc_train: 0.7466 acc_val: 0.7404\n",
      "Epoch: 0006 loss_train: 0.5789 acc_train: 0.6808 acc_val: 0.6617\n",
      "Epoch: 0007 loss_train: 0.5578 acc_train: 0.6812 acc_val: 0.6778\n",
      "Epoch: 0008 loss_train: 0.5247 acc_train: 0.7433 acc_val: 0.7345\n",
      "Epoch: 0009 loss_train: 0.4968 acc_train: 0.7861 acc_val: 0.7704\n",
      "Epoch: 0010 loss_train: 0.4993 acc_train: 0.7952 acc_val: 0.7886\n",
      "Epoch: 0011 loss_train: 0.4929 acc_train: 0.7945 acc_val: 0.7835\n",
      "Epoch: 0012 loss_train: 0.4776 acc_train: 0.7973 acc_val: 0.7856\n",
      "Epoch: 0013 loss_train: 0.4722 acc_train: 0.7978 acc_val: 0.7839\n",
      "Epoch: 0014 loss_train: 0.4641 acc_train: 0.7966 acc_val: 0.7877\n",
      "Epoch: 0015 loss_train: 0.4557 acc_train: 0.7961 acc_val: 0.7848\n",
      "Epoch: 0016 loss_train: 0.4624 acc_train: 0.7937 acc_val: 0.7844\n",
      "Epoch: 0017 loss_train: 0.4515 acc_train: 0.7956 acc_val: 0.7877\n",
      "Epoch: 0018 loss_train: 0.4521 acc_train: 0.7973 acc_val: 0.7932\n",
      "Epoch: 0019 loss_train: 0.4365 acc_train: 0.8027 acc_val: 0.7953\n",
      "Epoch: 0020 loss_train: 0.4385 acc_train: 0.8024 acc_val: 0.7928\n",
      "Epoch: 0021 loss_train: 0.4532 acc_train: 0.8027 acc_val: 0.7941\n",
      "Epoch: 0022 loss_train: 0.4424 acc_train: 0.8036 acc_val: 0.7958\n",
      "Epoch: 0023 loss_train: 0.4299 acc_train: 0.8054 acc_val: 0.7987\n",
      "Epoch: 0024 loss_train: 0.4259 acc_train: 0.8043 acc_val: 0.8017\n",
      "Epoch: 0025 loss_train: 0.4177 acc_train: 0.8136 acc_val: 0.8097\n",
      "Epoch: 0026 loss_train: 0.4256 acc_train: 0.8178 acc_val: 0.8085\n",
      "Epoch: 0027 loss_train: 0.4242 acc_train: 0.8231 acc_val: 0.8135\n",
      "Epoch: 0028 loss_train: 0.4038 acc_train: 0.8217 acc_val: 0.8161\n",
      "Epoch: 0029 loss_train: 0.3951 acc_train: 0.8252 acc_val: 0.8190\n",
      "Epoch: 0030 loss_train: 0.3935 acc_train: 0.8266 acc_val: 0.8186\n",
      "Epoch: 0031 loss_train: 0.3915 acc_train: 0.8300 acc_val: 0.8254\n",
      "Epoch: 0032 loss_train: 0.3926 acc_train: 0.8312 acc_val: 0.8254\n",
      "Epoch: 0033 loss_train: 0.3829 acc_train: 0.8368 acc_val: 0.8313\n",
      "Epoch: 0034 loss_train: 0.3813 acc_train: 0.8381 acc_val: 0.8288\n",
      "Epoch: 0035 loss_train: 0.3805 acc_train: 0.8368 acc_val: 0.8330\n",
      "Epoch: 0036 loss_train: 0.3785 acc_train: 0.8395 acc_val: 0.8304\n",
      "Epoch: 0037 loss_train: 0.3754 acc_train: 0.8403 acc_val: 0.8300\n",
      "Epoch: 0038 loss_train: 0.3738 acc_train: 0.8450 acc_val: 0.8342\n",
      "Epoch: 0039 loss_train: 0.3745 acc_train: 0.8430 acc_val: 0.8359\n",
      "Epoch: 0040 loss_train: 0.3734 acc_train: 0.8451 acc_val: 0.8389\n",
      "Epoch: 0041 loss_train: 0.3722 acc_train: 0.8437 acc_val: 0.8364\n",
      "Epoch: 0042 loss_train: 0.3669 acc_train: 0.8428 acc_val: 0.8385\n",
      "Epoch: 0043 loss_train: 0.3645 acc_train: 0.8424 acc_val: 0.8385\n",
      "Epoch: 0044 loss_train: 0.3639 acc_train: 0.8454 acc_val: 0.8376\n",
      "Epoch: 0045 loss_train: 0.3607 acc_train: 0.8450 acc_val: 0.8389\n",
      "Epoch: 0046 loss_train: 0.3583 acc_train: 0.8463 acc_val: 0.8376\n",
      "Epoch: 0047 loss_train: 0.3576 acc_train: 0.8445 acc_val: 0.8364\n",
      "Epoch: 0048 loss_train: 0.3565 acc_train: 0.8462 acc_val: 0.8389\n",
      "Epoch: 0049 loss_train: 0.3575 acc_train: 0.8474 acc_val: 0.8389\n",
      "Epoch: 0050 loss_train: 0.3531 acc_train: 0.8457 acc_val: 0.8381\n",
      "Epoch: 0051 loss_train: 0.3524 acc_train: 0.8467 acc_val: 0.8419\n",
      "Epoch: 0052 loss_train: 0.3518 acc_train: 0.8474 acc_val: 0.8389\n",
      "Epoch: 0053 loss_train: 0.3501 acc_train: 0.8482 acc_val: 0.8381\n",
      "Epoch: 0054 loss_train: 0.3493 acc_train: 0.8484 acc_val: 0.8389\n",
      "Epoch: 0055 loss_train: 0.3468 acc_train: 0.8502 acc_val: 0.8402\n",
      "Epoch: 0056 loss_train: 0.3459 acc_train: 0.8490 acc_val: 0.8376\n",
      "Epoch: 0057 loss_train: 0.3445 acc_train: 0.8492 acc_val: 0.8393\n",
      "Epoch: 0058 loss_train: 0.3442 acc_train: 0.8529 acc_val: 0.8355\n",
      "Epoch: 0059 loss_train: 0.3446 acc_train: 0.8508 acc_val: 0.8402\n",
      "Epoch: 0060 loss_train: 0.3416 acc_train: 0.8540 acc_val: 0.8364\n",
      "Epoch: 0061 loss_train: 0.3401 acc_train: 0.8515 acc_val: 0.8372\n",
      "Epoch: 0062 loss_train: 0.3381 acc_train: 0.8531 acc_val: 0.8406\n",
      "Epoch: 0063 loss_train: 0.3390 acc_train: 0.8527 acc_val: 0.8440\n",
      "Epoch: 0064 loss_train: 0.3365 acc_train: 0.8567 acc_val: 0.8397\n",
      "Epoch: 0065 loss_train: 0.3365 acc_train: 0.8537 acc_val: 0.8402\n",
      "Epoch: 0066 loss_train: 0.3352 acc_train: 0.8548 acc_val: 0.8414\n",
      "Epoch: 0067 loss_train: 0.3339 acc_train: 0.8561 acc_val: 0.8410\n",
      "Epoch: 0068 loss_train: 0.3327 acc_train: 0.8568 acc_val: 0.8427\n",
      "Epoch: 0069 loss_train: 0.3337 acc_train: 0.8555 acc_val: 0.8444\n",
      "Epoch: 0070 loss_train: 0.3313 acc_train: 0.8581 acc_val: 0.8397\n",
      "Epoch: 0071 loss_train: 0.3297 acc_train: 0.8579 acc_val: 0.8431\n",
      "Epoch: 0072 loss_train: 0.3303 acc_train: 0.8596 acc_val: 0.8427\n",
      "Epoch: 0073 loss_train: 0.3287 acc_train: 0.8590 acc_val: 0.8406\n",
      "Epoch: 0074 loss_train: 0.3283 acc_train: 0.8602 acc_val: 0.8444\n",
      "Epoch: 0075 loss_train: 0.3299 acc_train: 0.8587 acc_val: 0.8397\n",
      "Epoch: 0076 loss_train: 0.3260 acc_train: 0.8623 acc_val: 0.8419\n",
      "Epoch: 0077 loss_train: 0.3261 acc_train: 0.8617 acc_val: 0.8423\n",
      "Epoch: 0078 loss_train: 0.3255 acc_train: 0.8613 acc_val: 0.8385\n",
      "Epoch: 0079 loss_train: 0.3242 acc_train: 0.8607 acc_val: 0.8444\n",
      "Epoch: 0080 loss_train: 0.3250 acc_train: 0.8607 acc_val: 0.8414\n",
      "Epoch: 0081 loss_train: 0.3233 acc_train: 0.8604 acc_val: 0.8410\n",
      "Epoch: 0082 loss_train: 0.3222 acc_train: 0.8625 acc_val: 0.8406\n",
      "Epoch: 0083 loss_train: 0.3225 acc_train: 0.8612 acc_val: 0.8385\n",
      "Epoch: 0084 loss_train: 0.3194 acc_train: 0.8631 acc_val: 0.8436\n",
      "Epoch: 0085 loss_train: 0.3190 acc_train: 0.8641 acc_val: 0.8397\n",
      "Epoch: 0086 loss_train: 0.3179 acc_train: 0.8641 acc_val: 0.8427\n",
      "Epoch: 0087 loss_train: 0.3177 acc_train: 0.8659 acc_val: 0.8389\n",
      "Epoch: 0088 loss_train: 0.3192 acc_train: 0.8617 acc_val: 0.8431\n",
      "Epoch: 0089 loss_train: 0.3176 acc_train: 0.8633 acc_val: 0.8465\n",
      "Epoch: 0090 loss_train: 0.3170 acc_train: 0.8629 acc_val: 0.8436\n",
      "Epoch: 0091 loss_train: 0.3127 acc_train: 0.8657 acc_val: 0.8368\n",
      "Epoch: 0092 loss_train: 0.3141 acc_train: 0.8657 acc_val: 0.8419\n",
      "Epoch: 0093 loss_train: 0.3147 acc_train: 0.8652 acc_val: 0.8423\n",
      "Epoch: 0094 loss_train: 0.3127 acc_train: 0.8660 acc_val: 0.8431\n",
      "Epoch: 0095 loss_train: 0.3109 acc_train: 0.8651 acc_val: 0.8469\n",
      "Epoch: 0096 loss_train: 0.3106 acc_train: 0.8682 acc_val: 0.8423\n",
      "Epoch: 0097 loss_train: 0.3090 acc_train: 0.8682 acc_val: 0.8469\n",
      "Epoch: 0098 loss_train: 0.3093 acc_train: 0.8677 acc_val: 0.8452\n",
      "Epoch: 0099 loss_train: 0.3068 acc_train: 0.8694 acc_val: 0.8406\n",
      "Epoch: 0100 loss_train: 0.3054 acc_train: 0.8694 acc_val: 0.8423\n",
      "Test set results: test_loss= 0.3520 test_accuracy= 0.8377 f1_score= 0.8586 mcc= 0.6757\n"
     ]
    }
   ],
   "source": [
    "from Src.model import BotGAT\n",
    "\n",
    "embedding_size,dropout,lr,weight_decay=128,0.3,1e-3,5e-3\n",
    "\n",
    "botGAT=BotGAT(num_prop_size=5,cat_prop_size=3,embedding_dimension=embedding_size).to(device)\n",
    "\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(botGAT.parameters(),\n",
    "                    lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "botGAT.apply(init_weights)\n",
    "\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    acc_train, loss_train = train(epoch,botGAT)\n",
    "    \n",
    "acc_test, loss_test, f1, mcc = test(botGAT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f55860-a443-40f9-afcd-6048e8ee31fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:45:05.562439Z",
     "iopub.status.busy": "2025-05-22T09:45:05.561777Z",
     "iopub.status.idle": "2025-05-22T09:45:15.888767Z",
     "shell.execute_reply": "2025-05-22T09:45:15.888105Z",
     "shell.execute_reply.started": "2025-05-22T09:45:05.562421Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 16:45:08 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/22 16:45:11 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/05/22 16:45:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run nosy-sloth-269 at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/7/runs/2b93c57275c3481c874ad697bae83be0\n",
      "🧪 View experiment at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/7\n"
     ]
    }
   ],
   "source": [
    "# Logging experiment results\n",
    "run_description = \"BotGAT runs with custom features graph instead of traditional graph building\"\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"embedding_size\": embedding_size,\n",
    "        \"dropout\": dropout,\n",
    "        \"learning_rate\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"epochs\": epochs,\n",
    "        \"optimiser\": \"AdamW\"\n",
    "    })\n",
    "\n",
    "    # Log final test metrics (replace with your actual variable values)\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\":acc_train.item() if isinstance(acc_train, torch.Tensor) else acc_train,\n",
    "        \"train_loss\": loss_train.item() if isinstance(acc_train, torch.Tensor) else loss_train,\n",
    "        \"test_accuracy\": acc_test.item() if isinstance(acc_test, torch.Tensor) else acc_test,\n",
    "        \"test_loss\": loss_test.item() if isinstance(loss_test, torch.Tensor) else loss_test,\n",
    "        \"f1_score\": f1,\n",
    "        \"matthew_coeff\": mcc\n",
    "        \n",
    "    })\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(botGAT)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    # Optionally log model\n",
    "    mlflow.pytorch.log_model(botGAT, \"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
